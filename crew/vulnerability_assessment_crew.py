import os
from crewai import Agent, Task, Crew, Process
from langchain.tools import tool
from .config.crew_config_manager import config_manager
from ..ai_tools.ai_provider import ai_manager, CredentialManager
from ..ai_tools.config_manager import global_config_manager


# Initialize the LLM through the AI provider manager
try:
    # Get the configured provider
    provider_name = global_config_manager.get_default_provider()
    default_model = global_config_manager.get_default_model(provider_name)
    
    # For now, we'll still use the LangChain-compatible OpenAI interface for CrewAI compatibility
    # In a full implementation, we'd need to create LangChain-compatible wrappers for our providers
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(model="gpt-4")  # Fallback to ensure compatibility with CrewAI
except:
    # Fallback to ensure compatibility with CrewAI
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(model="gpt-4")

# Define custom tools for the vulnerability assessment crew
@tool("list_files")
def list_files(directory: str) -> str:
    """List all files in a directory"""
    try:
        files = os.listdir(directory)
        return f"Files in {directory}: {', '.join(files)}"
    except Exception as e:
        return f"Error listing files: {str(e)}"

@tool("read_file")
def read_file(file_path: str) -> str:
    """Read the contents of a file"""
    try:
        with open(file_path, 'r') as f:
            return f.read()
    except Exception as e:
        return f"Error reading file: {str(e)}"

@tool("security_scanner")
def security_scanner(file_path: str) -> str:
    """Scan a file for common security vulnerabilities"""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        
        vulnerabilities = []
        
        # Check for potential security issues
        if "eval(" in content:
            vulnerabilities.append("Potential code injection via eval()")
        if "exec(" in content:
            vulnerabilities.append("Potential code injection via exec()")
        if "os.system(" in content or "subprocess.call(" in content:
            vulnerabilities.append("Potential command injection")
        if "password" in content.lower() and ("=" in content or "var" in content):
            vulnerabilities.append("Potential hardcoded credential")
        if "sql" in content.lower() and "select" in content.lower() and "from" in content.lower():
            if "param" not in content.lower() and "escape" not in content.lower():
                vulnerabilities.append("Potential SQL injection")
        if "jwt_secret" in content.lower() or "secret_key" in content.lower():
            vulnerabilities.append("Potential hardcoded secret key")
        
        if vulnerabilities:
            return f"Security issues found in {file_path}: {', '.join(vulnerabilities)}"
        else:
            return f"No obvious security issues found in {file_path}"
    except Exception as e:
        return f"Error scanning file: {str(e)}"

@tool("dependency_checker")
def dependency_checker() -> str:
    """Check project dependencies for known vulnerabilities"""
    import subprocess
    try:
        # Check if requirements.txt exists
        if os.path.exists("requirements.txt"):
            # Use pip-audit if available to check for vulnerabilities
            result = subprocess.run(
                ["pip-audit", "-r", "requirements.txt"] if os.path.exists("requirements.txt") 
                else ["echo", "pip-audit not found or requirements.txt missing"],
                capture_output=True, text=True
            )
            return result.stdout if result.stdout else "No dependency issues found or pip-audit not installed"
        else:
            return "requirements.txt not found"
    except Exception as e:
        return f"Error checking dependencies: {str(e)}"


def create_vulnerability_assessment_crew():
    """Create the vulnerability assessment crew based on the configuration"""
    config = config_manager.get_config("vulnerability_assessment_crew")
    
    if not config:
        raise ValueError("Vulnerability assessment crew configuration not found")
    
    # Create agents based on configuration
    agents_config = config["agents"]
    agents = {}
    
    for agent_config in agents_config:
        agent_name = agent_config["name"]
        
        if agent_name == "security_analyst":
            agent = Agent(
                role=agent_config["role"],
                goal=agent_config["goal"],
                backstory=agent_config["backstory"],
                verbose=True,
                allow_delegation=False,
                llm=llm,
                tools=[list_files, read_file, security_scanner]
            )
        elif agent_name == "code_auditor":
            agent = Agent(
                role=agent_config["role"],
                goal=agent_config["goal"],
                backstory=agent_config["backstory"],
                verbose=True,
                allow_delegation=False,
                llm=llm,
                tools=[read_file, dependency_checker]
            )
        elif agent_name == "report_generator":
            agent = Agent(
                role=agent_config["role"],
                goal=agent_config["goal"],
                backstory=agent_config["backstory"],
                verbose=True,
                allow_delegation=False,
                llm=llm
            )
        else:
            # Default agent creation for any other agents
            agent = Agent(
                role=agent_config["role"],
                goal=agent_config["goal"],
                backstory=agent_config["backstory"],
                verbose=True,
                allow_delegation=False,
                llm=llm
            )
        
        agents[agent_name] = agent
    
    # Create tasks based on configuration
    tasks_config = config["tasks"]
    tasks = []
    
    for task_config in tasks_config:
        task_name = task_config["name"]
        
        # Map task to the appropriate agent
        if task_name == "security_scan_task":
            agent = agents["security_analyst"]
        elif task_name == "detailed_analysis_task":
            agent = agents["code_auditor"]
        elif task_name == "report_generation_task":
            agent = agents["report_generator"]
        else:
            # Default to the first agent if not specifically mapped
            agent = list(agents.values())[0]
        
        task = Task(
            description=task_config["description"],
            agent=agent,
            expected_output=task_config["expected_output"]
        )
        
        # Add context if specified
        if "context" in task_config:
            # For now, we'll add a simple note about context
            # In a real implementation, you'd link tasks properly
            task.description += f"\n\nContext from previous tasks: {task_config['context']}"
        
        tasks.append(task)
    
    # Create the crew
    vulnerability_crew = Crew(
        agents=list(agents.values()),
        tasks=tasks,
        process=Process.sequential,  # Execute tasks in sequence as configured
        verbose=config["verbose"]
    )
    
    return vulnerability_crew


# For testing the vulnerability assessment crew independently
if __name__ == "__main__":
    print("Creating vulnerability assessment crew...")
    vuln_crew = create_vulnerability_assessment_crew()
    
    print("Starting vulnerability assessment crew process...")
    result = vuln_crew.kickoff()
    
    print("Vulnerability assessment crew completed.")
    print("Result:", result)